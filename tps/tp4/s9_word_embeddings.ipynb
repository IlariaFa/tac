{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings : le modèle Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/ilaria/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de documents CAMille : 1000000\n",
      "Nombre d'articles TP4 : 999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle Word2Vec global entraîné.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle Word2Vec TP4 entraîné.\n",
      "\n",
      "Voisins sémantiques - Modèle global\n",
      "--- Voisins de 'sorcière' ---\n",
      "montagnarde           0.957\n",
      "bégayait              0.954\n",
      "rictus                0.953\n",
      "convulsion            0.953\n",
      "reportait             0.952\n",
      "soubrette             0.950\n",
      "pauvresse             0.948\n",
      "duègne                0.948\n",
      "méphistophélès        0.947\n",
      "aliénée               0.947\n",
      "--- Voisins de 'sorcellerie' ---\n",
      "phénoménal            0.953\n",
      "maffia                0.952\n",
      "contestait            0.952\n",
      "discutables           0.951\n",
      "virulence             0.951\n",
      "incarné               0.951\n",
      "hanter                0.951\n",
      "eqfin                 0.951\n",
      "érotisme              0.950\n",
      "halves                0.950\n",
      "--- Voisins de 'femme' ---\n",
      "mariée                0.751\n",
      "femmo                 0.721\n",
      "enfant                0.710\n",
      "fillo                 0.695\n",
      "fille                 0.680\n",
      "fillette              0.679\n",
      "blanchisseuse         0.678\n",
      "orpheline             0.677\n",
      "tille                 0.673\n",
      "homme                 0.669\n",
      "--- Voisins de 'féminisme' ---\n",
      "énerve                0.940\n",
      "étonnerait            0.937\n",
      "poursuivons           0.936\n",
      "raidissement          0.934\n",
      "impres                0.933\n",
      "erroné                0.933\n",
      "lyrisme               0.933\n",
      "dépeinte              0.933\n",
      "réfléchie             0.932\n",
      "bouffonne             0.932\n",
      "--- Voisins de 'procès' ---\n",
      "verbal                0.769\n",
      "condamnation          0.763\n",
      "rinchard              0.745\n",
      "confirmé              0.739\n",
      "verdict               0.738\n",
      "intenté               0.738\n",
      "diffamation           0.735\n",
      "jugement              0.731\n",
      "acquittement          0.728\n",
      "accusé                0.727\n",
      "--- Voisins de 'homme' ---\n",
      "hommo                 0.812\n",
      "garçon                0.697\n",
      "hommé                 0.685\n",
      "jeune                 0.673\n",
      "gamin                 0.669\n",
      "femme                 0.669\n",
      "bomme                 0.666\n",
      "employé               0.663\n",
      "instruit              0.656\n",
      "intelligent           0.650\n",
      "--- Voisins de 'justice' ---\n",
      "paix                  0.707\n",
      "jugo                  0.696\n",
      "juge                  0.691\n",
      "pais                  0.668\n",
      "justices              0.664\n",
      "compétente            0.664\n",
      "conformement          0.656\n",
      "injustice             0.656\n",
      "comparution           0.648\n",
      "prétoire              0.646\n",
      "\n",
      "### Similarité: sorcière ↔ femme\n",
      "Global: 0.522\n",
      "TP4: 0.605\n",
      "\n",
      "### Similarité: sorcière ↔ procès\n",
      "Global: 0.484\n",
      "TP4: 0.430\n",
      "\n",
      "### Similarité: femme ↔ homme\n",
      "Global: 0.669\n",
      "TP4: 0.652\n",
      "Vecteurs embeddings exportés.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n"
     ]
    }
   ],
   "source": [
    "# --- IMPORTS ---\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "# --- CHEMINS ---\n",
    "corpus_path = \"../../data/sents.txt\"      # Corpus complet CAMille\n",
    "articles_dir = \"../../data/txt_tp4/\"      # Vos articles filtrés TP4\n",
    "\n",
    "# --- FONCTIONS UTILITAIRES ---\n",
    "def tokenize(text):\n",
    "    \"\"\"Tokenisation et nettoyage léger.\"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^\\w\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [t for t in tokens if len(t) > 2]\n",
    "    return tokens\n",
    "\n",
    "# --- CHARGEMENT DES DONNÉES ---\n",
    "# Corpus complet\n",
    "with open(corpus_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    all_texts = f.readlines()\n",
    "all_texts = [t.strip() for t in all_texts if t.strip()]\n",
    "print(f\"Nombre de documents CAMille : {len(all_texts)}\")\n",
    "\n",
    "# Articles TP4\n",
    "files = sorted([f for f in os.listdir(articles_dir) if f.endswith(\".txt\")])\n",
    "tp4_texts = [open(os.path.join(articles_dir, f), \"r\", encoding=\"utf-8\").read() for f in files]\n",
    "print(f\"Nombre d'articles TP4 : {len(tp4_texts)}\")\n",
    "\n",
    "# --- TOKENISATION ---\n",
    "tokenized_all = [tokenize(t) for t in all_texts]\n",
    "tokenized_tp4 = [tokenize(t) for t in tp4_texts]\n",
    "\n",
    "# --- ENTRAÎNEMENT Word2Vec GLOBAL (tout CAMille) ---\n",
    "model_global = Word2Vec(\n",
    "    sentences=tokenized_all,\n",
    "    vector_size=100,\n",
    "    window=5,\n",
    "    min_count=3,\n",
    "    workers=4,\n",
    "    sg=1  # skip-gram\n",
    ")\n",
    "model_global.save(\"w2v_global.model\")\n",
    "print(\"Modèle Word2Vec global entraîné.\")\n",
    "\n",
    "# --- OPTION : Word2Vec pour les articles TP4 ---\n",
    "model_tp4 = Word2Vec(\n",
    "    sentences=tokenized_tp4,\n",
    "    vector_size=100,\n",
    "    window=5,\n",
    "    min_count=2,\n",
    "    workers=4,\n",
    "    sg=1\n",
    ")\n",
    "model_tp4.save(\"w2v_tp4.model\")\n",
    "print(\"Modèle Word2Vec TP4 entraîné.\")\n",
    "\n",
    "# --- EXPLORATION / VOISINS SEMANTIQUES ---\n",
    "keywords = [\"sorcière\", \"sorcellerie\", \"femme\", \"féminisme\", \"procès\", \"homme\", \"justice\"]\n",
    "\n",
    "def show_neighbors(word, model, topn=10):\n",
    "    if word not in model.wv:\n",
    "        print(f\"'{word}' absent du vocabulaire.\")\n",
    "        return\n",
    "    print(f\"--- Voisins de '{word}' ---\")\n",
    "    for w, score in model.wv.most_similar(word, topn=topn):\n",
    "        print(f\"{w:20s}  {score:.3f}\")\n",
    "\n",
    "print(\"\\nVoisins sémantiques - Modèle global\")\n",
    "for kw in keywords:\n",
    "    show_neighbors(kw, model_global)\n",
    "\n",
    "# --- COMPARAISON ENTRE WORDS ---\n",
    "def compare_similarity(word1, word2, models_dict):\n",
    "    print(f\"\\n### Similarité: {word1} ↔ {word2}\")\n",
    "    for name, model in models_dict.items():\n",
    "        if word1 in model.wv and word2 in model.wv:\n",
    "            sim = model.wv.similarity(word1, word2)\n",
    "            print(f\"{name}: {sim:.3f}\")\n",
    "        else:\n",
    "            print(f\"{name}: absent\")\n",
    "\n",
    "compare_similarity(\"sorcière\", \"femme\", {\"Global\": model_global, \"TP4\": model_tp4})\n",
    "compare_similarity(\"sorcière\", \"procès\", {\"Global\": model_global, \"TP4\": model_tp4})\n",
    "compare_similarity(\"femme\", \"homme\", {\"Global\": model_global, \"TP4\": model_tp4})\n",
    "\n",
    "# --- EXPORT DES VECTEURS POUR ANALYSES ---\n",
    "EXPORT_DIR = \"w2v_exports\"\n",
    "os.makedirs(EXPORT_DIR, exist_ok=True)\n",
    "\n",
    "embeddings_export = []\n",
    "for word in keywords:\n",
    "    for model_name, model in {\"Global\": model_global, \"TP4\": model_tp4}.items():\n",
    "        if word not in model.wv:\n",
    "            continue\n",
    "        vec = model.wv[word]\n",
    "        embeddings_export.append({\n",
    "            \"model\": model_name,\n",
    "            \"word\": word,\n",
    "            \"vector\": vec.tolist()\n",
    "        })\n",
    "\n",
    "with open(os.path.join(EXPORT_DIR, \"embedding_vectors.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(embeddings_export, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"Vecteurs embeddings exportés.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
